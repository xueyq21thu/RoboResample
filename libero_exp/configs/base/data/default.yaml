# benchmark related
benchmark_envs: ["libero_spatial", "libero_object", "libero_goal", "libero_90", "libero_10", "libero_100"]
env_name: "libero_object"
root_dir: "/mnt/disk_2/guanxing/xueyq21thu/libero" 

task_order_index: 0                 # if 0, demo list is [demo_0, demo_1, ...]
train_ratio: 0.9                    # use xx% as trainset
val_demo_num: 5

data_modality:
  - "image"
  - "proprio"
seq_len: 10
frame_stack: 1
use_eye_in_hand: true
use_gripper: true
use_joint: true
use_ee: false
obs:
  modality:
    rgb: ["agentview_rgb", "eye_in_hand_rgb"]
    depth: []
    low_dim: ["gripper_states", "joint_states"]
img_size: 128

# mapping from obs.modality keys to robosuite environment observation keys
obs_key_mapping:
  agentview_rgb: agentview_image
  eye_in_hand_rgb: robot0_eye_in_hand_image
  gripper_states: robot0_gripper_qpos
  joint_states: robot0_joint_pos

# language
embedding_model_path: "/mnt/disk_2/guanxing/xueyq21thu/bert-base-cased" 
task_embedding_format: "bert"       # language tokenizer
max_word_len: 25
